# 实验心得

## 实验背景  
本次实验基于 PyTorch 框架，涉及两种深度学习模型的实现与训练：  
1. **CNN 模型（Chen）**：用于 CIFAR-10 图像分类任务  
2. **Vision Transformer (ViT)**：适配时间序列分类任务  

实验内容包括：  
- 自定义数据集加载 (`ImageTxtDataset`)  
- 模型定义 (`model.py` 和 `transformer.py`)  
- 训练脚本实现 (`train.py`)  

---

## 实验过程与收获  

### 数据集准备与预处理  
**收获**：  
- 实现 `ImageTxtDataset` 从文本文件加载图像路径和标签  
- 掌握 `torchvision.transforms` 进行数据增强（缩放、归一化、随机翻转）  
- 理解数据管道对模型训练的重要性  

**挑战**：  
- 硬编码路径（如 `D:\python.learm\shixun\day3\train.txt`）导致环境迁移问题  

**改进建议**：  
- 使用相对路径或命令行参数提高可移植性  
- 修复 `ImageTxtDataset` 中注释掉的 `os.path.join`（确保路径正确拼接）  

---

### 模型设计与实现  
#### CNN 模型（Chen）  
**收获**：  
- 验证模型结构：输入 `(64, 3, 32, 32)` → 输出 `(64, 10)`  
- 理解卷积层参数与特征图尺寸变化（手动计算 `32×32 → 4×4×64 = 1024`）  

**挑战**：  
- 全连接层假设输入特征固定为 `1024`，需严格匹配输入尺寸  

**改进建议**：  
- 添加 `nn.AdaptiveAvgPool2d` 提高输入尺寸鲁棒性  

#### ViT 模型  
**收获**：  
- 时间序列分块处理（`seq_len=256, patch_size=16`）  
- 使用 `einops` 库优雅处理张量变换（`rearrange`, `pack`, `unpack`）  
- 验证输出形状：`(4, 1000)`  

**挑战**：  
- 参数量大（`dim=1024, depth=6, heads=8`），计算资源需求高  
- 初始未打印输出导致误判代码问题  

**改进建议**：  
- 调整 `num_classes=10` 以匹配 CIFAR-10  
- 适配图像分类任务（修改 `Rearrange` 为 2D patch 切分）  

---

### 模型训练与评估  
**收获**：  
- 完整训练流程实现：数据加载 → 损失计算（`CrossEntropyLoss`） → 优化（`SGD`） → 可视化（`TensorBoard`） → 模型保存  
- 通过监控 `loss` 和 `accuracy` 评估性能  
- 标签检查（`targets.max() >= num_classes`）避免错误  

**挑战**：  
- 10 轮训练后模型可能未收敛（学习率 `0.01` 需调整）  
- ViT 未整合到 `train.py` 中  

**改进建议**：  
1. 引入学习率调度（如 `torch.optim.lr_scheduler`）  
2. 在 `train.py` 中对比 CNN 和 ViT 性能  
3. 增加早停机制（`early stopping`）  

---

### 调试与问题解决  
**关键技巧**：  
- 通过 `print(logits)` 验证 ViT 输出形状 `(4, 1000)`  
- 打印中间张量维度定位问题  

**改进建议**：  
- 在 ViT 各模块（`to_patch_embedding`, `transformer`, `mlp_head`）中添加形状打印  

---

## 心得体会  
1. **数据处理**：掌握自定义数据集构建与预处理流程  
2. **模型设计**：对比 CNN 的局部特征提取与 Transformer 的全局建模能力  
3. **训练优化**：学会使用 `TensorBoard` 可视化和模型保存  
4. **调试能力**：通过张量打印快速定位问题  

---

## 未来计划  
1. **模型优化**：调整超参数（学习率、ViT patch 大小等）  
2. **任务扩展**：将 ViT 适配图像分类，与 CNN 对比  
3. **代码鲁棒性**：改用配置文件管理路径和参数  
4. **实验扩展**：尝试其他数据集（如 ImageNet 子集）或任务（时间序列预测）  

---

## 总结  
通过本次实验：  
- 实践了从数据加载到模型训练的完整流程  
- 深入理解 CNN 和 Transformer 的设计思想  
- 提升代码调试与性能优化能力  

**下一步**：持续优化模型，探索更多深度学习应用场景！